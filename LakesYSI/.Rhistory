con <- dbConnect(odbc(),
Driver = "MS Access Database",
dsn = awx_data_insert.accdb)
access_file <- "C:/Users/deepuser/Documents/Projects/wqDB_docs/awx_data_insert.accdb"
access_file <- "C:/Users/deepuser/Documents/Projects/wqDB_docs/awx_data_insert.accdb"
# Connect to the MySQL database: con
con <- dbConnect(odbc(),
Driver = "MS Access Database",
dsn = access_file)
library('RSQLite')
library('dplyr')
library('stringr')
# legacy <- c(16119, 19940, 16122, 16120, 15014, 17852,
#             16191, 16416, 14866, 20123)
# open ODBC
db_path <- 'C:/Users/deepuser/Documents/Projects/DiatomData/'
db <- dbConnect(SQLite(), dbname=paste(db_path,"diatom_data.db",sep=''));
# Select data to calculate CT TP metrics
SQL <- "SELECT
counts.staSeq,
Samples.locationName,
counts.date,
counts.duplicate,
SUM(counts.count) AS SumCnts,
ct_tol.tolcl,
Samples.sampleCnt
FROM counts
JOIN
ct_tol ON counts.shortName = ct_tol.taxa
JOIN
Samples ON counts.staSeq = Samples.staSeq AND
counts.date = Samples.date AND
counts.duplicate = Samples.duplicate
GROUP BY counts.staSeq,
Samples.locationName,
counts.date,
counts.duplicate,
ct_tol.tolcl,
Samples.sampleCnt;"
d_TP <- dbGetQuery(conn=db,SQL); #returns data.frame
SQL <- "SELECT * FROM stations;"
s   <- dbGetQuery(conn=db,SQL)
dbDisconnect(db)
d_TP$RA <- d_TP$SumCnts / d_TP$sampleCnt
# Separate out tolerant TP and sensitive TP diatom metrics
d_RAtol <- arrange(d_TP[d_TP$tolcl == 'Increasing',c(1:3,8)],desc(RA))
d_RAsen <- arrange(d_TP[d_TP$tolcl == 'Decreasing',c(1:3,8)],desc(RA))
hi_RAtol <- unique(d_RAtol[d_RAtol$RA>=0.25,1])
s_hi_RAtol <- s[s$staSeq%in%hi_RAtol,]
hi_RAtol
s_hi_RAtol
View(s_hi_RAtol)
d_TP
d_TP
d_TP[1:10,]
class(d_TP$date)
max(substr(d_TP$,1,4))
max(substr(d_TP$date,1,4))
min(substr(d_TP$date,1,4))
d_TP[d_TP$locationName=="Pequabuck River",]
install.packages("rmarkdown", dependencies = TRUE)
plot(cars)
knitr::opts_chunk$set(echo = TRUE)
summary(cars)
plot(pressure)
library(rmarkdown)
install.packages("leaflet")
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE)
library(leaflet)
m <- leaflet() %>% setView(lng = -72.6999, lat = 41.5999, zoom = 12)
m %>% addTiles()
library(leaflet)
m <- leaflet() %>% setView(lng = -72.6999, lat = 41.5999, zoom = 9)
m %>% addTiles()
library(leaflet)
m <- leaflet() %>% setView(lng = -72.6999, lat = 41.5999, zoom = 9)
m %>% addProviderTiles(providers$CartoDB.Voyager)
install.packages("sf")
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE)
# set working directory
setwd("C:/Users/deepuser/Documents/Projects/ProgramDev/HQStreamEval/")
library(leaflet)
library(sf)
#read in data
d <- read.csv("data/bug_bcg_sites_020422.csv",header=TRUE)
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE)
library(leaflet)
library(sf)
#read in data
d <- read.csv("data/bug_bcg_sites_020422.csv",header=TRUE)
m <- leaflet() %>% setView(lng = -72.6999, lat = 41.5999, zoom = 9)
m %>%
addProviderTiles(providers$CartoDB.Voyager)
names(d)
sp_d <- SpatialPointsDataFrame(coords = d[,c(YLAT,XLONG)], data = d, proj4string = CRS("+proj=longlat +datum=WGS84"))
library(sf)
sp_d <- SpatialPointsDataFrame(coords = d[,c(YLAT,XLONG)], data = d, proj4string = CRS("+proj=longlat +datum=WGS84"))
library(spatial)
library(sp)
sp_d <- SpatialPointsDataFrame(coords = d[,c(YLAT,XLONG)], data = d, proj4string = CRS("+proj=longlat +datum=WGS84"))
sp_d <- SpatialPointsDataFrame(coords = d[,c("YLAT","XLONG")], data = d, proj4string = CRS("+proj=longlat +datum=WGS84"))
library(leaflet)
library(sp)
# read in data
d <- read.csv("data/bug_bcg_sites_020422.csv",header=TRUE)
# convert to spatial point dataframe
sp_d <- SpatialPointsDataFrame(coords = d[,c("YLAT","XLONG")], data = d, proj4string = CRS("+proj=longlat +datum=WGS84"))
m <- leaflet(data = sp_d) %>% setView(lng = -72.6999, lat = 41.5999, zoom = 9)
m %>%
addProviderTiles(providers$CartoDB.Voyager) %>%
addMarkers(~XLONG, ~YLAT)
library(leaflet)
library(sp)
# read in data
d <- read.csv("data/bug_bcg_sites_020422.csv",header=TRUE)
# convert to spatial point dataframe
sp_d <- SpatialPointsDataFrame(coords = d[,c("YLAT","XLONG")], data = d, proj4string = CRS("+proj=longlat +datum=WGS84"))
m <- leaflet(data = sp_d) %>% setView(lng = -72.6999, lat = 41.5999, zoom = 9)
m %>%
addProviderTiles(providers$CartoDB.Voyager) %>%
addCircleMarkersMarkers(~XLONG, ~YLAT, radius = 6, stroke = FALSE, fillOpacity = 0.5)
library(leaflet)
library(sp)
# read in data
d <- read.csv("data/bug_bcg_sites_020422.csv",header=TRUE)
# convert to spatial point dataframe
sp_d <- SpatialPointsDataFrame(coords = d[,c("YLAT","XLONG")], data = d, proj4string = CRS("+proj=longlat +datum=WGS84"))
m <- leaflet(data = sp_d) %>% setView(lng = -72.6999, lat = 41.5999, zoom = 9)
m %>%
addProviderTiles(providers$CartoDB.Voyager) %>%
addCircleMarkers(~XLONG, ~YLAT, radius = 6, stroke = FALSE, fillOpacity = 0.5)
render("bcg_data_exploration.Rmd")
library(rmarkdown)
render("C:\\Users\\deepuser\\Documents\\Projects\\ProgramDev\\HQStreamEval\\analysis\\bcg_data_exploration.Rmd")
knitr::opts_chunk$set(message=FALSE, warning=FALSE)
library(leaflet)
library(sp)
# read in data
d <- read.csv("data/bug_bcg_sites_020422.csv",header=TRUE)
# Number of Sites in the dataset
dim(d)[1]
render("C:\\Users\\deepuser\\Documents\\Projects\\ProgramDev\\HQStreamEval\\analysis\\bcg_data_exploration.Rmd")
names(d)
# convert to spatial point dataframe
sp_d <- SpatialPointsDataFrame(coords = d[,c("YLAT","XLONG")],
data = d,
proj4string = CRS("+proj=longlat +datum=WGS84"))
m <- leaflet(data = sp_d) %>% setView(lng = -72.6999, lat = 41.5999, zoom = 9)
m %>%
addProviderTiles(providers$CartoDB.Voyager) %>%
addCircleMarkers(~XLONG, ~YLAT, radius = 6, stroke = FALSE, fillOpacity = 0.5,
label = ~paste("Site ID & Name:",STASEQ,NAME))
# convert to spatial point dataframe
sp_d <- SpatialPointsDataFrame(coords = d[,c("YLAT","XLONG")],
data = d,
proj4string = CRS("+proj=longlat +datum=WGS84"))
m <- leaflet(data = sp_d) %>% setView(lng = -72.6999, lat = 41.5999, zoom = 9)
m %>%
addProviderTiles(providers$CartoDB.Voyager) %>%
addCircleMarkers(~XLONG, ~YLAT, radius = 6, stroke = FALSE, fillOpacity = 0.5,
label = ~NAME)
render("C:\\Users\\deepuser\\Documents\\Projects\\ProgramDev\\HQStreamEval\\analysis\\bcg_data_exploration.Rmd")
render("C:\\Users\\deepuser\\Documents\\Projects\\ProgramDev\\HQStreamEval\\analysis\\bcg_data_exploration.Rmd")
install.packages("bookdown",dependencies = TRUE)
library(httr)
library(jsonlite)
base <- 'https://five.epicollect.net/api/export/entries/'
cID<- '3022'
secret <- 'eUEvkOCJaFPMk2gTLowO02ABWrwnT8jp8V9ZMBRC'
proj.slug <- 'ct-deep-benthic-algae-sampling-2021'
form.ref <- 'form_ref=96d692d25d8f4d2fb01aae2e3f9678ac_607706a867716'
res <- POST("https://five.epicollect.net/api/oauth/token",
body = list(grant_type = "client_credentials",
client_id = cID,
client_secret = secret))
http_status(res)
token <- content(res)$access_token
url.form<- paste(base,
proj.slug,
"?map_index=&",
form.ref,
"&format=json&headers=true",
sep= "")
res1<- GET(url.form, add_headers("Authorization" = paste("Bearer", token)))
http_status(res1)
ct1<- fromJSON(rawToChar(content(res1)))
data <- ct1$data$entries
data <- data[,6:12]
data$staSeq <- substr(data[,1],1,5)
data[1:10,]
data[,1]
names(data)
library(httr)
library(jsonlite)
base <- 'https://five.epicollect.net/api/export/entries/'
cID<- '3022'
secret <- 'eUEvkOCJaFPMk2gTLowO02ABWrwnT8jp8V9ZMBRC'
proj.slug <- 'ct-deep-benthic-algae-sampling-2021'
form.ref <- 'form_ref=96d692d25d8f4d2fb01aae2e3f9678ac_607706a867716'
res <- POST("https://five.epicollect.net/api/oauth/token",
body = list(grant_type = "client_credentials",
client_id = cID,
client_secret = secret))
http_status(res)
token <- content(res)$access_token
url.form<- paste(base,
proj.slug,
"?map_index=&",
form.ref,
"&format=json&headers=true",
sep= "")
res1<- GET(url.form, add_headers("Authorization" = paste("Bearer", token)))
http_status(res1)
ct1<- fromJSON(rawToChar(content(res1)))
data <- ct1$data$entries
data <- data[,6:12]
data$staSeq <- substr(data[,1],1,5)
data[1:2]
data[1:2,]
names(data)
data[,3]
data$prj_id <- "benthicAlgABM"
data$s_date <- paste0(substr(data$`4_Date`,1,4),"-",
substr(data$`4_Date`,6,7),"-",
substr(data$`4_Date`,8,9))
data[1:2,]
data$s_date <- paste0(substr(data$`4_Date`,1,4),"-",
substr(data$`4_Date`,6,7),"-",
substr(data$`4_Date`,9,10))
data[1:2,]
setwd("C:/Users/deepuser/Documents/Projects/ProgramDev/Lakes/LakesYSI/")
library(ggplot2)
library(grid)
library(gridExtra)
library(rgdal)
library(sp)
library(sf)
library(png)
library(tmap)
library(dplyr)
library(pdftools)
##Read in Lakes ysi and secchi data"
ysi<-read.csv("data/LakesYSI_2012_2021.csv",header=TRUE,stringsAsFactors = FALSE)
ysi$chlor_rfu<-ifelse(ysi$chlor_rfu <= 0,0,ysi$chlor_rfu)
#ysi <- ysi[,1:25]
samples<-read.csv("data/Samples_2012_2021.csv",header=TRUE,stringsAsFactors = FALSE)
ysisampleck<-unique(ysi[c("awq","date")])
samples<-merge(ysisampleck,samples,by=c("awq","date"))
lakespoly<-read_sf("data/lakes_poly.geojson")
lakespts<-read_sf("data/lakes_pt.geojson")
cttownspoly<-read_sf("data/CTTowns.geojson")
maxtemp<- max(ysi$temp)
maxdo<-max(ysi$do_mgl)
maxchlor<-max(ysi$chlor_rfu)
maxbga<-max(ysi$bga_rfu)
samples
samples[samples$awq==18953,]
samples[ysi$STA_SEQ==18953,]
ysi
samples[samples$awq==18953,]
ysi[ysi$awq==18953,]
samples[1:10,]
dim(samples)[1]
##Read in Lakes ysi and secchi data"
ysi<-read.csv("data/LakesYSI_2012_2021.csv",header=TRUE,stringsAsFactors = FALSE)
ysi$chlor_rfu<-ifelse(ysi$chlor_rfu <= 0,0,ysi$chlor_rfu)
#ysi <- ysi[,1:25]
samples<-read.csv("data/Samples_2012_2021.csv",header=TRUE,stringsAsFactors = FALSE)
ysisampleck<-unique(ysi[c("awq","date")])
samples<-merge(ysisampleck,samples,by=c("awq","date"))
##Read in Lakes geospatial data"
lakespoly<-read_sf("data/lakes_poly.geojson")
lakespts<-read_sf("data/lakes_pt.geojson")
cttownspoly<-read_sf("data/CTTowns.geojson")
##X axis limits - Max value for each parameter
maxtemp<- max(ysi$temp)
maxdo<-max(ysi$do_mgl)
maxchlor<-max(ysi$chlor_rfu)
maxbga<-max(ysi$bga_rfu)
for (i in 1:dim(samples)[1]){
st<-samples$awq[i]
dt<-samples$date[i]
s<-ysi[which(ysi$awq==st&ysi$date==dt),]
s<-s[order(s$depth),]
p1<-  ggplot(s,aes(temp,depth))+
geom_path(size=1.5)+
scale_y_reverse(limits=c(max(s$depth),0))+
xlim(0,maxtemp)+
labs(y="Depth (m)",x=expression(paste("Temperature (",degree,"C)")),
title=expression(paste("Temperature (",degree,"C)")))+
theme_classic()+
theme(text=element_text(size=14))+
theme(plot.margin=unit(c(1,1,1.5,1.5),"cm"))
p2<-  ggplot(s,aes(do_mgl,depth))+
geom_path(size=1.5)+
scale_y_reverse(limits=c(max(s$depth),0))+
xlim(0,maxdo)+
labs(y="Depth (m)",x="Dissolved Oxygen (mg/L)",title="Dissolved Oxygen (mg/L)")+
theme_classic()+
theme(text=element_text(size=14))+
theme(plot.margin=unit(c(1,1,1.5,1.5),"cm"))
p3<-  ggplot(s,aes(chlor_rfu,depth))+
geom_path(size=1.5)+
scale_y_reverse(limits=c(max(s$depth),0))+
xlim(0,maxchlor)+
labs(y="Depth (m)",x="Chlorophyll (rfu)",
title="Chlorophyll (rfu)")+
theme_classic()+
theme(text=element_text(size=14))+
theme(plot.margin=unit(c(1,1,1.5,1.5),"cm"))
p4<-  ggplot(s,aes(bga_rfu,depth))+
geom_path(size=1.5)+
scale_y_reverse(limits=c(max(s$depth),0))+
xlim(0,maxbga)+
labs(y="Depth (m)",x="Phycocyanin Blue-Green Algae (rfu)",
title="Phycocyanin (rfu)")+
theme_classic()+
theme(text=element_text(size=14))+
theme(plot.margin=unit(c(1,1,1.5,1.5),"cm"))
##Parse out the lake data that you are interested in
lakemappt<-lakespts[which(lakespts$STA_SEQ==st),]
lakemappoly<-lakespoly[which(lakespoly$GNIS_ID==lakemappt$GNIS_ID),]
##Make a map of the parsed lake data
smap<-  tm_shape(cttownspoly)+
tm_polygons(col="gray",border.col="white",lwd=2)+
tm_shape(lakemappt)+
tm_symbols(col="black")+
tm_layout(bg.color="midnightblue")
lmap<-  tm_shape(lakemappoly)+
tm_polygons(col="deepskyblue1",border.col="white",lwd=3,border.alpha=0.7)+
tm_shape(lakemappt)+
tm_symbols(col="black")+
tm_layout(bg.color="midnightblue")
wmap<-tmap_arrange(smap,lmap)
tmap_save(wmap,paste0("maps/",st,"map.png"),width=600,height=400,dpi=72)
map<-readPNG(paste0("maps/",st,"map.png"))
lay<-rbind(c(1,2),
c(3,2),
c(4,2),
c(5,2),
c(NA,2),
c(NA,6),
c(NA,7),
c(NA,8),
c(9,10),
c(11,12))
infojust<-0
posx<-0.01
posy<-1
title<-textGrob(paste0(lakemappt$name," (SID ",st,")"),
gp=gpar(fontsize=25,fontface="bold", col="black"),posx,posy,just=infojust)
sdate<-textGrob(paste("Sample Date:",dt),
gp=gpar(fontsize=15,fontface="bold", col="black"),posx,posy,just=infojust)
secchi<-textGrob(paste("Secchi Depth (m):",format(round(samples$secchi_m[i],2),nsmall=2)),
gp=gpar(fontsize=15,fontface="bold", col="black"),posx,posy,just=infojust)
depth<-textGrob(paste("Total Depth (m):",format(round(samples$tdepth_m[i],2),nsmall=2)),
gp=gpar(fontsize=15,fontface="bold", col="black"),posx,posy,just=infojust)
acre<-textGrob(paste("Acres:",round(lakemappoly$area_acre,2)),posx,posy,just=infojust)
town<-textGrob(paste("Town:",lakemappt$town),posx,posy,just=infojust)
basin<-textGrob(paste("Drainage Basin:",lakemappt$sbas_nm),posx,posy,just=infojust)
map<-rasterGrob(map)
laketest<-grid.arrange(title,map,sdate,secchi,depth,acre,town,basin,p1,p2,p3,p4,
ncol=2,layout_matrix=lay,
heights=unit(c(0.5,0.5,0.5,0.5,1,0.25,0.25,0.25,3,3),
c("in","in","in","in","in","in","in","in","in")))
ggsave(paste0("ysipdf/",st,lakemappt$name,gsub('/','-',dt),"ysi.pdf"),laketest,width=8,height=11,units="in",dpi=72)
}
unique(ysi$name)
unique(samples$name)
st
dt
p1
p21
p2
p3
p4
s
lakemappt$name
lakemappt
lakespts$name
setwd("C:/Users/deepuser/Documents/Projects/ProgramDev/Lakes/LakesYSI/")
library(ggplot2)
library(grid)
library(gridExtra)
library(rgdal)
library(sp)
library(sf)
library(png)
library(tmap)
library(dplyr)
library(pdftools)
##Read in Lakes ysi and secchi data"
ysi<-read.csv("data/LakesYSI_2012_2021.csv",header=TRUE,stringsAsFactors = FALSE)
ysi$chlor_rfu<-ifelse(ysi$chlor_rfu <= 0,0,ysi$chlor_rfu)
#ysi <- ysi[,1:25]
samples<-read.csv("data/Samples_2012_2021.csv",header=TRUE,stringsAsFactors = FALSE)
ysisampleck<-unique(ysi[c("awq","date")])
samples<-merge(ysisampleck,samples,by=c("awq","date"))
##Read in Lakes geospatial data"
lakespoly<-read_sf("data/lakes_poly.geojson")
lakespts<-read_sf("data/lakes_pt.geojson")
cttownspoly<-read_sf("data/CTTowns.geojson")
##X axis limits - Max value for each parameter
maxtemp<- max(ysi$temp)
maxdo<-max(ysi$do_mgl)
maxchlor<-max(ysi$chlor_rfu)
maxbga<-max(ysi$bga_rfu)
##Generate a pdf for each lake in the dataset
for (i in 1:dim(samples)[1]){
st<-samples$awq[i]
dt<-samples$date[i]
s<-ysi[which(ysi$awq==st&ysi$date==dt),]
s<-s[order(s$depth),]
p1<-  ggplot(s,aes(temp,depth))+
geom_path(size=1.5)+
scale_y_reverse(limits=c(max(s$depth),0))+
xlim(0,maxtemp)+
labs(y="Depth (m)",x=expression(paste("Temperature (",degree,"C)")),
title=expression(paste("Temperature (",degree,"C)")))+
theme_classic()+
theme(text=element_text(size=14))+
theme(plot.margin=unit(c(1,1,1.5,1.5),"cm"))
p2<-  ggplot(s,aes(do_mgl,depth))+
geom_path(size=1.5)+
scale_y_reverse(limits=c(max(s$depth),0))+
xlim(0,maxdo)+
labs(y="Depth (m)",x="Dissolved Oxygen (mg/L)",title="Dissolved Oxygen (mg/L)")+
theme_classic()+
theme(text=element_text(size=14))+
theme(plot.margin=unit(c(1,1,1.5,1.5),"cm"))
p3<-  ggplot(s,aes(chlor_rfu,depth))+
geom_path(size=1.5)+
scale_y_reverse(limits=c(max(s$depth),0))+
xlim(0,maxchlor)+
labs(y="Depth (m)",x="Chlorophyll (rfu)",
title="Chlorophyll (rfu)")+
theme_classic()+
theme(text=element_text(size=14))+
theme(plot.margin=unit(c(1,1,1.5,1.5),"cm"))
p4<-  ggplot(s,aes(bga_rfu,depth))+
geom_path(size=1.5)+
scale_y_reverse(limits=c(max(s$depth),0))+
xlim(0,maxbga)+
labs(y="Depth (m)",x="Phycocyanin Blue-Green Algae (rfu)",
title="Phycocyanin (rfu)")+
theme_classic()+
theme(text=element_text(size=14))+
theme(plot.margin=unit(c(1,1,1.5,1.5),"cm"))
##Parse out the lake data that you are interested in
lakemappt<-lakespts[which(lakespts$STA_SEQ==st),]
lakemappoly<-lakespoly[which(lakespoly$GNIS_ID==lakemappt$GNIS_ID),]
##Make a map of the parsed lake data
smap<-  tm_shape(cttownspoly)+
tm_polygons(col="gray",border.col="white",lwd=2)+
tm_shape(lakemappt)+
tm_symbols(col="black")+
tm_layout(bg.color="midnightblue")
lmap<-  tm_shape(lakemappoly)+
tm_polygons(col="deepskyblue1",border.col="white",lwd=3,border.alpha=0.7)+
tm_shape(lakemappt)+
tm_symbols(col="black")+
tm_layout(bg.color="midnightblue")
wmap<-tmap_arrange(smap,lmap)
tmap_save(wmap,paste0("maps/",st,"map.png"),width=600,height=400,dpi=72)
map<-readPNG(paste0("maps/",st,"map.png"))
lay<-rbind(c(1,2),
c(3,2),
c(4,2),
c(5,2),
c(NA,2),
c(NA,6),
c(NA,7),
c(NA,8),
c(9,10),
c(11,12))
infojust<-0
posx<-0.01
posy<-1
title<-textGrob(paste0(lakemappt$name," (SID ",st,")"),
gp=gpar(fontsize=25,fontface="bold", col="black"),posx,posy,just=infojust)
sdate<-textGrob(paste("Sample Date:",dt),
gp=gpar(fontsize=15,fontface="bold", col="black"),posx,posy,just=infojust)
secchi<-textGrob(paste("Secchi Depth (m):",format(round(samples$secchi_m[i],2),nsmall=2)),
gp=gpar(fontsize=15,fontface="bold", col="black"),posx,posy,just=infojust)
depth<-textGrob(paste("Total Depth (m):",format(round(samples$tdepth_m[i],2),nsmall=2)),
gp=gpar(fontsize=15,fontface="bold", col="black"),posx,posy,just=infojust)
acre<-textGrob(paste("Acres:",round(lakemappoly$area_acre,2)),posx,posy,just=infojust)
town<-textGrob(paste("Town:",lakemappt$town),posx,posy,just=infojust)
basin<-textGrob(paste("Drainage Basin:",lakemappt$sbas_nm),posx,posy,just=infojust)
map<-rasterGrob(map)
laketest<-grid.arrange(title,map,sdate,secchi,depth,acre,town,basin,p1,p2,p3,p4,
ncol=2,layout_matrix=lay,
heights=unit(c(0.5,0.5,0.5,0.5,1,0.25,0.25,0.25,3,3),
c("in","in","in","in","in","in","in","in","in")))
ggsave(paste0("ysipdf/",st,lakemappt$name,gsub('/','-',dt),"ysi.pdf"),laketest,width=8,height=11,units="in",dpi=72)
}
lf<-as.data.frame(list.files("ysipdf"))
lf$sid<-substr(lf[,1],1,5)
lf$cnt<-1
cntpdf<-aggregate(lf[c("cnt")],by=lf[c("sid")],sum)
for (i in 1:dim(cntpdf)[1]){
if (cntpdf[i,2]>1){
pdfjoin<-lf[lf$sid==cntpdf[i,1],]
pdfjoin$file<-paste0("ysipdf/",pdfjoin$`list.files("ysipdf")`)
pdf_combine(pdfjoin[,4],paste0('ysipdf/bysite/',pdfjoin[1,2],'.pdf'))
}
if (cntpdf[i,2]==1){
pdf<-lf[lf$sid==cntpdf[i,1],]
pdf$file<-paste0("ysipdf/",pdf$`list.files("ysipdf")`)
file.copy(pdf$file,paste0('ysipdf/bysite/',pdf$sid,'.pdf'))
}
}
